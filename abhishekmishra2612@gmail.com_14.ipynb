{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "abhishekmishra2612@gmail.com_14.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr4cugH3mZ_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import Dense,concatenate,Activation,Dropout,Input,LSTM,Flatten,BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# fix random seed for reproducibility\n",
        "np.random.seed(7)\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plwqBm2rOZkR",
        "colab_type": "code",
        "outputId": "d55231d9-7af0-40ae-960f-9ee889774932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cks_YDAvOv6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/data/preprocessed_data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIlemxtRPQav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(Data.drop([\"project_is_approved\"],axis=1),Data[\"project_is_approved\"],test_size=0.25,random_state=42,stratify=Data[\"project_is_approved\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrLAlluyPT_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "essay=x_train[\"essay\"].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFOLQxTQRJzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "essay_words=[]\n",
        "for sent in essay:\n",
        "  essay_words.extend(sent.split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ8E6VznR7V0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_words=list(set(essay_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xNErpHedIzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign a unique number to each word in the vocab.\n",
        "\n",
        "vocab_dict=dict(zip(unique_words,list(np.arange(1,len(unique_words)+1))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ODPpUT0iFY7",
        "colab_type": "code",
        "outputId": "362154c6-03ba-4c6f-bc3b-d393997e37ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab=vocab_dict.keys()\n",
        "len(vocab)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50476"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2cSLCMLmzAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_essay_train=[]\n",
        "for sent in essay:\n",
        "  if(len(set(sent.split()).intersection(set(vocab)))>=1):\n",
        "    vector=[]\n",
        "    for word in sent.split():\n",
        "      if(word in vocab):\n",
        "        vector.append(vocab_dict[word])\n",
        "    new_essay_train.append(vector)  \n",
        "  else:\n",
        "    vector=[]\n",
        "    for word in sent.split():\n",
        "      vector.append(0)\n",
        "    new_essay_train.append(vector)      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4TQms5jq5Z9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_essay_test=[]\n",
        "for sent in x_test[\"essay\"].values:\n",
        "  if(len(set(sent.split()).intersection(set(vocab)))>=1):\n",
        "    vector=[]\n",
        "    for word in sent.split():\n",
        "      if(word in vocab):\n",
        "        vector.append(vocab_dict[word])\n",
        "    new_essay_test.append(vector)  \n",
        "  else:\n",
        "    vector=[]\n",
        "    for word in sent.split():\n",
        "      vector.append(0)\n",
        "    new_essay_test.append(vector)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC2zOYIZmE5C",
        "colab_type": "code",
        "outputId": "496cadf8-5715-4107-be5d-c166f3eb3998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pd.DataFrame(new_essay_train).shape\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(81936, 331)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aHAuJuEvrtWQ",
        "outputId": "42d17fac-c0da-46b9-ae87-c5d082e437f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pd.DataFrame(new_essay_test).shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27312, 333)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JufJfbzz2a3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_review_length = 400\n",
        "essay_train = sequence.pad_sequences(new_essay_train, maxlen=max_review_length)\n",
        "essay_test = sequence.pad_sequences(new_essay_test, maxlen=max_review_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwAh6yONMTOt",
        "colab_type": "code",
        "outputId": "154e2f81-6016-485b-e17c-4cff1ce4a9cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "essay_test.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27312, 400)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jR9vDJB6Jdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states=list(set(x_train[\"school_state\"].values))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXN4OqK_72ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=[value for value in range(1,len(states)+1)]\n",
        "school_states_codes=dict(zip(states,a))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zip0coREpObd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "school_state_train=[]\n",
        "for st in x_train[\"school_state\"].values:\n",
        "  if(st in states):\n",
        "     school_state_train.append(school_states_codes[st])\n",
        "  else:\n",
        "     school_state_train.append(0)   \n",
        " \n",
        "   \n",
        "school_state_test=[]\n",
        "for st in x_test[\"school_state\"].values:\n",
        "  if(st in states):\n",
        "    school_state_test.append(school_states_codes[st])\n",
        "  else:\n",
        "    school_state_test.append(0)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufI4oPOjuunj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prefixes=list(set(x_train[\"teacher_prefix\"].values))\n",
        "b=[value for value in range(1,len(prefixes)+1)]\n",
        "teacher_prefix_codes=dict(zip(prefixes,b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dExZPbigu1pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher_prefix_train=[]\n",
        "for pre in x_train[\"teacher_prefix\"].values:\n",
        "  if(pre in prefixes):\n",
        "     teacher_prefix_train.append(teacher_prefix_codes[pre])\n",
        "  else:\n",
        "     teacher_prefix_train.append(0)   \n",
        "     \n",
        "  \n",
        "teacher_prefix_test = []\n",
        "for pre in x_test[\"teacher_prefix\"].values:\n",
        "  if(pre in prefixes):\n",
        "     teacher_prefix_test.append(teacher_prefix_codes[pre])\n",
        "  else:\n",
        "     teacher_prefix_test.append(0)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK-1K6WcxS50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grades=list(set(x_train[\"project_grade_category\"].values))\n",
        "c=[value for value in range(1,len(grades)+1)]\n",
        "project_grade_codes=dict(zip(grades,c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcYuKJLZyGde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_grade_train=[]\n",
        "for pre in x_train[\"project_grade_category\"].values:\n",
        "  if(pre in grades):\n",
        "    project_grade_train.append(project_grade_codes[pre])\n",
        "  else:\n",
        "    project_grade_train.append(0)  \n",
        "\n",
        "   \n",
        "\n",
        "project_grade_test=[]\n",
        "for pre in x_test[\"project_grade_category\"].values:\n",
        "  if(pre in grades):\n",
        "     project_grade_test.append(project_grade_codes[pre])\n",
        "  else:\n",
        "     project_grade_test.append(0)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpm9u8Z1yyvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories=list(set(x_train[\"clean_categories\"].values))\n",
        "d=[value for value in range(1,len(categories)+1)]\n",
        "categories_codes=dict(zip(categories,d))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4308XdDazaHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories_train=[]\n",
        "for pre in x_train[\"clean_categories\"].values:\n",
        "  if(pre in categories):\n",
        "    categories_train.append(categories_codes[pre])\n",
        "  else:\n",
        "    categories_train.append(0)  \n",
        "   \n",
        "\n",
        "categories_test=[]\n",
        "for pre in x_test[\"clean_categories\"].values:\n",
        "  if(pre in categories):\n",
        "     categories_test.append(categories_codes[pre])\n",
        "  else:\n",
        "    categories_test.append(0)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdd9c1A50Qk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subcategories=list(set(x_train[\"clean_subcategories\"].values))\n",
        "e=[value for value in range(1,len(subcategories)+1)]\n",
        "subcategories_codes=dict(zip(subcategories,e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GV5Zmk80bjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subcategories_train=[]\n",
        "for pre in x_train[\"clean_subcategories\"].values:\n",
        "  if(pre in subcategories):\n",
        "    subcategories_train.append(subcategories_codes[pre])\n",
        "  else:\n",
        "    subcategories_train.append(0)  \n",
        "\n",
        "   \n",
        "\n",
        "subcategories_test=[]\n",
        "for pre in x_test[\"clean_subcategories\"].values:\n",
        "  if(pre in subcategories):\n",
        "     subcategories_test.append(subcategories_codes[pre])\n",
        "  else:\n",
        "    subcategories_test.append(0)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6MDyPRz00pY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_variable_train = np.array([list(value) for value in zip(x_train[\"teacher_number_of_previously_posted_projects\"].values,x_train[\"price\"].values)])\n",
        "\n",
        "num_variable_test = np.array([list(value) for value in zip(x_test[\"teacher_number_of_previously_posted_projects\"].values,x_test[\"price\"].values)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZd-RSYdMoQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler=StandardScaler()\n",
        "\n",
        "num_variable_train = scaler.fit_transform(num_variable_train)\n",
        "num_variable_test = scaler.transform(num_variable_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K__6nj94bmeZ",
        "colab_type": "text"
      },
      "source": [
        "========================================================================================================\n",
        "# Model-1\n",
        "======================================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrjiT-ls8Oel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_input_layer=Input(shape=(400,))\n",
        "school_input_layer=Input(shape=(1,))\n",
        "teacher_prefix_input_layer=Input(shape=(1,))\n",
        "project_grade_input_layer=Input(shape=(1,))\n",
        "categories_input_layer=Input(shape=(1,))\n",
        "subcategories_input_layer=Input(shape=(1,))\n",
        "number_input_layer=Input(shape=(2,))\n",
        "\n",
        "embedding_layer_text=Embedding(len(vocab), 100 , input_length=400)(text_input_layer)\n",
        "dropout_before_lstm=Dropout(0.2)(embedding_layer_text)\n",
        "lstm_layer=LSTM(100,input_shape=(400,100))(dropout_before_lstm)\n",
        "#flatten=Flatten()(lstm_layer) # did not use this because output of LSTM for each sequence is a vector.\n",
        "embedding_layer_school=Embedding(len(states),4 , input_length=1)(school_input_layer)\n",
        "flatten_1=Flatten()(embedding_layer_school)\n",
        "embedding_layer_teacher_prefix=Embedding(len(prefixes),2,input_length=1)(teacher_prefix_input_layer)\n",
        "flatten_2=Flatten()(embedding_layer_teacher_prefix)\n",
        "embedding_layer_project_grade=Embedding(len(grades),2,input_length=1)(project_grade_input_layer)\n",
        "flatten_3=Flatten()(embedding_layer_project_grade)\n",
        "embedding_layer_categories=Embedding(len(categories),8,input_length=1)(categories_input_layer)\n",
        "flatten_4=Flatten()(embedding_layer_categories)\n",
        "embedding_layer_subcategories=Embedding(len(subcategories),16,input_length=1)(subcategories_input_layer)\n",
        "flatten_5=Flatten()(embedding_layer_subcategories)\n",
        "dense_layer_num=Dense(16,activation=\"relu\",kernel_initializer=\"he_normal\")(number_input_layer)\n",
        "\n",
        "concat_layer=concatenate([lstm_layer,flatten_1,flatten_2,flatten_3,flatten_4,flatten_5,dense_layer_num])\n",
        "\n",
        "dropout_layer_after_concat=Dropout(0.2)(concat_layer)\n",
        "dense_layer_after_concat=Dense(32,activation=\"relu\",kernel_initializer=\"he_normal\")(dropout_layer_after_concat)\n",
        "dropout_after_dense=Dropout(0.5)(dense_layer_after_concat)\n",
        "dense_layer_2=Dense(32,activation=\"relu\",kernel_initializer=\"he_normal\")(dropout_after_dense)\n",
        "dropout_2=Dropout(0.5)(dense_layer_2)\n",
        "dense_layer_3=Dense(16,activation=\"relu\",kernel_initializer=\"he_normal\")(dropout_2)\n",
        "bn=BatchNormalization()(dense_layer_3)\n",
        "\n",
        "output_layer=Dense(1,activation=\"sigmoid\")(bn)\n",
        "\n",
        "model_1=Model(inputs=[text_input_layer,school_input_layer,teacher_prefix_input_layer,project_grade_input_layer,categories_input_layer,subcategories_input_layer,number_input_layer],outputs=output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KPzsDlGos18",
        "colab_type": "code",
        "outputId": "36bec620-9852-4c63-cfdd-e8fed019831d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 400)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 400, 100)     5047600     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 400, 100)     0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 1, 4)         204         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 1, 2)         10          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 1, 2)         8           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 1, 8)         408         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 1, 16)        6352        input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            (None, 2)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 100)          80400       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 4)            0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 2)            0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 2)            0           embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 8)            0           embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 16)           0           embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 16)           48          input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 148)          0           lstm_1[0][0]                     \n",
            "                                                                 flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "                                                                 flatten_4[0][0]                  \n",
            "                                                                 flatten_5[0][0]                  \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 148)          0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32)           4768        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           1056        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 16)           528         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 16)           64          dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            17          batch_normalization_1[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 5,141,463\n",
            "Trainable params: 5,141,431\n",
            "Non-trainable params: 32\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQNFJbREonUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn import metrics\n",
        "from keras import backend as K\n",
        "\n",
        "def auc(y_true, y_pred):\n",
        "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
        "    K.get_session().run(tf.local_variables_initializer())\n",
        "    return auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7oDzJLG8Oa3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[auc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiOE_Q9o8OYb",
        "colab_type": "code",
        "outputId": "259e5592-d674-4947-9680-bb05cf2133a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "history_1 = model_1.fit([np.array(essay_train),np.array(school_state_train),np.array(teacher_prefix_train),np.array(project_grade_train),np.array(categories_train),np.array(subcategories_train),np.array(num_variable_train)],y_train,epochs=15,batch_size=128,verbose=1,validation_data=([np.array(essay_test),np.array(school_state_test),np.array(teacher_prefix_test),np.array(project_grade_test),np.array(categories_test),np.array(subcategories_test),np.array(num_variable_test)],y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 81936 samples, validate on 27312 samples\n",
            "Epoch 1/15\n",
            "81936/81936 [==============================] - 431s 5ms/step - loss: 0.4794 - auc: 0.5096 - val_loss: 0.4241 - val_auc: 0.5105\n",
            "Epoch 2/15\n",
            "81936/81936 [==============================] - 412s 5ms/step - loss: 0.4195 - auc: 0.5276 - val_loss: 0.4023 - val_auc: 0.5541\n",
            "Epoch 3/15\n",
            "81936/81936 [==============================] - 410s 5ms/step - loss: 0.4122 - auc: 0.5721 - val_loss: 0.4262 - val_auc: 0.5811\n",
            "Epoch 4/15\n",
            "81936/81936 [==============================] - 410s 5ms/step - loss: 0.3933 - auc: 0.5944 - val_loss: 0.4029 - val_auc: 0.6110\n",
            "Epoch 5/15\n",
            "81936/81936 [==============================] - 404s 5ms/step - loss: 0.3685 - auc: 0.6288 - val_loss: 0.4105 - val_auc: 0.6433\n",
            "Epoch 6/15\n",
            "81936/81936 [==============================] - 405s 5ms/step - loss: 0.3458 - auc: 0.6581 - val_loss: 0.4064 - val_auc: 0.6709\n",
            "Epoch 7/15\n",
            "81936/81936 [==============================] - 406s 5ms/step - loss: 0.3184 - auc: 0.6846 - val_loss: 0.4080 - val_auc: 0.6962\n",
            "Epoch 8/15\n",
            "81936/81936 [==============================] - 405s 5ms/step - loss: 0.2906 - auc: 0.7088 - val_loss: 0.4024 - val_auc: 0.7196\n",
            "Epoch 9/15\n",
            "81936/81936 [==============================] - 405s 5ms/step - loss: 0.2588 - auc: 0.7314 - val_loss: 0.4354 - val_auc: 0.7408\n",
            "Epoch 10/15\n",
            "81936/81936 [==============================] - 405s 5ms/step - loss: 0.2286 - auc: 0.7512 - val_loss: 0.4494 - val_auc: 0.7598\n",
            "Epoch 11/15\n",
            "81936/81936 [==============================] - 411s 5ms/step - loss: 0.2009 - auc: 0.7690 - val_loss: 0.4594 - val_auc: 0.7768\n",
            "Epoch 12/15\n",
            "81936/81936 [==============================] - 420s 5ms/step - loss: 0.1780 - auc: 0.7849 - val_loss: 0.5066 - val_auc: 0.7919\n",
            "Epoch 13/15\n",
            "81936/81936 [==============================] - 421s 5ms/step - loss: 0.1575 - auc: 0.7990 - val_loss: 0.4672 - val_auc: 0.8053\n",
            "Epoch 14/15\n",
            "81936/81936 [==============================] - 422s 5ms/step - loss: 0.1400 - auc: 0.8118 - val_loss: 0.5287 - val_auc: 0.8172\n",
            "Epoch 15/15\n",
            "81936/81936 [==============================] - 421s 5ms/step - loss: 0.1286 - auc: 0.8227 - val_loss: 0.5313 - val_auc: 0.8275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uyNb6khfr1S",
        "colab_type": "code",
        "outputId": "cfd6f978-6aa1-4a5e-f6da-127f9e8723c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "scores=model_1.evaluate([np.array(essay_test),np.array(school_state_test),np.array(teacher_prefix_test),np.array(project_grade_test),np.array(categories_test),np.array(subcategories_test),np.array(num_variable_test)],y_test,verbose=0)\n",
        "print(\"Loss =\",scores[0],\"\\nAUC =\",scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.5313214336177656 \n",
            "AUC = 0.8244108017523106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSuvHWAV5Csd",
        "colab_type": "text"
      },
      "source": [
        "=======================================================================================================\n",
        "# Model-2\n",
        "======================================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FMoKsrGrJ_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "\n",
        "tfidf_vec=TfidfVectorizer()\n",
        "tfidf_essay=tfidf_vec.fit_transform(essay)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK7qfDRfrKG_",
        "colab_type": "code",
        "outputId": "1bec7fee-adfe-4e67-84b7-24486c41b15b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "sns.boxplot(x=tfidf_vec.idf_)\n",
        "plt.show()\n",
        "\n",
        "sns.distplot(tfidf_vec.idf_)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWIAAAD4CAYAAADW1uzrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dfXRcd33n8fd3ZjR69IMeHCVYdmwH\n8xBCSIiOHQgFuSHB0G7SFvYQF9i0JevdPQRaurSHbM8STtizm1263bIlLXhTb+guidul0HqpSwik\nIqRpgp3AJnFCEsc2thQ7tvVkj55mRvPdP+aOM5JH0kgaaa4un9c5k7n3d59+v9j+6Oo3v/sbc3dE\nRCS6YtWugIiILC4FvYhIxCnoRUQiTkEvIhJxCnoRkYhLVLsCpbS1tfmGDRsAGB4eprGxsboVqiC1\nJ9zUnnBTe6b35JNPnnH3NaW2hTLoN2zYwIEDBwDo7u6mq6uruhWqILUn3NSecFN7pmdmP5tum7pu\nREQiTkEvIhJxCnoRkYhT0IuIRJyCXkQk4hT0IiIRp6AXEYk4Bb2ISMQp6EVEIi6UT8aKiCwH9z9x\nrGT5r29dv8Q1mZnu6EVEIk5BLyIScQp6EZGIU9CLiEScgl5EJOJmHXVjZruBXwZOufsVJbb/HvCR\novO9GVjj7v1mdhQ4B0wAWXfvrFTFRUSkPOXc0d8HbJ9uo7t/0d2vcvergDuAH7h7f9Eu24LtCnkR\nkSqYNejd/RGgf7b9AjuABxZUIxERqaiK9dGbWQP5O/+/Lip24Ltm9qSZ7azUtUREpHzm7rPvZLYB\n+HapPvqifT4MfNTd/1lR2Vp37zWzi4CHgE8GvyGUOn4nsBOgvb39mj179gCQSqVoamoqu0Fhp/aE\nm9oTbmFrT/9wumR5S2OyrOMr2Z5t27Y9OV0XeSWnQLiFKd027t4bvJ8ys28BW4CSQe/uu4BdAJ2d\nnV74wlx9GXC4qT3hpvYsrummQOgqcwqEpWpPRbpuzGwV8B7gb4vKGs1sRWEZuBF4thLXExGR8pUz\nvPIBoAtoM7Me4E6gBsDdvxLs9qvAd919uOjQduBbZla4zv3u/p3KVV1ERMoxa9C7+44y9rmP/DDM\n4rLDwNvmWzEREakMPRkrIhJxCnoRkYhT0IuIRJyCXkQk4hT0IiIRp6AXEYk4Bb2ISMQp6EVEIk5B\nLyIScQp6EZGIU9CLiEScgl5EJOIU9CIiEaegFxGJOAW9iEjEKehFRCJOQS8iEnEKehGRiFPQi4hE\nnIJeRCTiZg16M9ttZqfM7NlptneZ2ZCZ/SR4fa5o23Yze8HMDpnZZytZcRERKU85d/T3Adtn2eeH\n7n5V8LoLwMziwD3A+4HLgR1mdvlCKisiInM3a9C7+yNA/zzOvQU45O6H3T0N7AFunsd5RERkAczd\nZ9/JbAPwbXe/osS2LuCvgR7gFeAz7n7QzD4EbHf324L9PgZsdffbp7nGTmAnQHt7+zV79uwBIJVK\n0dTUNOeGhZXaE25qT7iFrT39w+mS5S2NybKOr2R7tm3b9qS7d5balqjA+Z8CLnX3lJl9APgbYPNc\nT+Luu4BdAJ2dnd7V1QVAd3c3heUoUHvCTe0Jt7C15/4njpUs79q6vqzjl6o9Cx514+5n3T0VLO8D\nasysDegF1hXt2hGUiYjIElpw0JvZxWZmwfKW4Jx9wH5gs5ltNLMkcAuwd6HXExGRuZm168bMHgC6\ngDYz6wHuBGoA3P0rwIeAf2NmWWAUuMXzHf9ZM7sdeBCIA7vd/eCitEJERKY1a9C7+45Ztn8Z+PI0\n2/YB++ZXNRERqQQ9GSsiEnEKehGRiFPQi4hEnIJeRCTiFPQiIhGnoBcRiTgFvYhIxCnoRUQiTkEv\nIhJxCnoRkYhT0IuIRJyCXkQk4hT0IiIRp6AXEYk4Bb2ISMQp6EVEIk5BLyIScQp6EZGIU9CLiETc\nrEFvZrvN7JSZPTvN9o+Y2dNm9oyZPWZmbyvadjQo/4mZHahkxUVEpDzl3NHfB2yfYfsR4D3u/lbg\nC8CuKdu3uftV7t45vyqKiMhCJGbbwd0fMbMNM2x/rGj1caBj4dUSEZFKMXeffad80H/b3a+YZb/P\nAG9y99uC9SPAAODAV9196t1+8bE7gZ0A7e3t1+zZsweAVCpFU1NTOW1ZFtSecFN7wi1s7ekfTpcs\nb2lMlnV8Jduzbdu2J6frOZn1jr5cZrYN+DjwrqLid7l7r5ldBDxkZj9190dKHR/8ENgF0NnZ6V1d\nXQB0d3dTWI4CtSfc1J5wC1t77n/iWMnyrq3ryzp+qdpTkVE3ZnYlcC9ws7v3FcrdvTd4PwV8C9hS\nieuJiEj5Fhz0ZrYe+CbwMXd/sai80cxWFJaBG4GSI3dERGTxzNp1Y2YPAF1Am5n1AHcCNQDu/hXg\nc0Ar8KdmBpAN+onagW8FZQngfnf/ziK0QUREZlDOqJsds2y/DbitRPlh4G0XHiEiIktJT8aKiESc\ngl5EJOIU9CIiEaegFxGJOAW9iEjEKehFRCJOQS8iEnEKehGRiFPQi4hEnIJeRCTiFPQiIhGnoBcR\niTgFvYhIxCnoRUQiTkEvIhJxCnoRkYhT0IuIRJyCXkQk4hT0IiIRV1bQm9luMztlZs9Os93M7L+b\n2SEze9rM3l607VYzeyl43VqpiouISHnKvaO/D9g+w/b3A5uD107gzwDMrAW4E9gKbAHuNLPm+VZW\nRETmrqygd/dHgP4ZdrkZ+AvPexxYbWaXAO8DHnL3fncfAB5i5h8YIiJSYYkKnWctcLxovScom678\nAma2k/xvA7S3t9Pd3Q1AKpU6vxwFak+4qT3hFrb21A2nS5Z3dx8u6/ilak+lgn7B3H0XsAugs7PT\nu7q6AOju7qawHAVqT7ipPeEWtvbc/8SxkuVdW9eXdfxStadSo256gXVF6x1B2XTlIiKyRCoV9HuB\nfxGMvrkWGHL3E8CDwI1m1hx8CHtjUCYiIkukrK4bM3sA6ALazKyH/EiaGgB3/wqwD/gAcAgYAX4z\n2NZvZl8A9genusvdZ/pQV0REKqysoHf3HbNsd+AT02zbDeyee9VERKQS9GSsiEjEKehFRCJOQS8i\nEnEKehGRiFPQi4hEnIJeRCTiFPQiIhX06EunebZ3qNrVmERBLyJSIUOjGfY9e5L7Hjta7apMoqAX\nEamQw6dTADzTozt6EZFIevn0MAAvnTrHaHqiyrV5jYJeRKQC3J2XT6eor4mTc3juRHju6hX0IiIV\n0D+cZmg0w7WbWgB4OkTdNwp6EZEKKHTbXLWumYtW1Iaqn15BLyJSAS+fTrGyLkFbU5IrO1bxdIiG\nWCroRUQWKOfO4dMpLlvThJlxxdpVvHw6xfB4ttpVAxT0IiILdursOMPpCTataQLgyo5VuMPBV85W\nuWZ5CnoRkQU6PjACwIbWBgCuWLsKgKd7BqtWp2IKehGRBRocSWPA6oYkABetqOPilXU8E5J+egW9\niMgCDY5kWFlfQzxm58ve2rEqNCNvygp6M9tuZi+Y2SEz+2yJ7f/NzH4SvF40s8GibRNF2/ZWsvIi\nImEwOJphdX3NpLJNaxrpGRgl/5Xa1TXrl4ObWRy4B7gB6AH2m9led3+usI+7f7po/08CVxedYtTd\nr6pclUVEwmVoNENHc/2ksrbGWtITOc6NZ1lZVzPNkUujnDv6LcAhdz/s7mlgD3DzDPvvAB6oROVE\nRMIu587QaIbV9clJ5a1N+fW+VLoa1Zpk1jt6YC1wvGi9B9haakczuxTYCDxcVFxnZgeALHC3u//N\nNMfuBHYCtLe3093dDUAqlTq/HAVqT7ipPeEWtvbUDac5m3Ymck5bro+6M/le6+7uw/Sezo+h/94P\nH2dzc7zk8UvVnnKCfi5uAb7h7sXTtl3q7r1mtgl42MyecfeXpx7o7ruAXQCdnZ3e1dUFQHd3N4Xl\nKFB7wk3tCbewtef+J47xav8I8DKNa9Yx1rYSgK6t61nzyhD/9clHWbf5LXRdcXHJ45eqPeV03fQC\n64rWO4KyUm5hSreNu/cG74eBbib334uILGuDoxkAVjdM7odva6oFoG94fMnrNFU5Qb8f2GxmG80s\nST7MLxg9Y2ZvApqBfyoqazaz2mC5DbgOeG7qsSIiy9XQSL4PfmoffXMwpv7MuWXQR+/uWTO7HXgQ\niAO73f2gmd0FHHD3QujfAuzxyWOJ3gx81cxy5H+o3F08WkdEZLkbHM2QTMSoq5l835xMxFhVXxOK\nO/qy+ujdfR+wb0rZ56asf77EcY8Bb11A/UREQm1wJD+G3swu2NbalAzFqBs9GSsisgBDo5kL+ucL\n2hprOZOq/h29gl5EZAEGRzOsqi8d9K1NSfqGdUcvIrJsZSZyDI9nWTXlg9iCfNeN7uhFRJatoWmG\nVha0NtYyMJIhO5FbympdQEEvIjJPgyNB0E/TddO2Ij+Wvn+kut03CnoRkXkaGg3G0DeU7rppawzH\nWHoFvYjIPA2OZDBgZV3pkeqtIXk6VkEvIjJPQ6MZmuoSJOKlozQsM1gq6EVE5mmmoZWQH0cPVH0s\nvYJeRGSe+ofT5+e0KWVlfYJEzKo+ll5BLyIyD9mJHIMjaVoapw96MwvFWHoFvYjIPJwYGiPn0DpD\n0EN+LL366EVElqFj/SMANM8W9E1JzqjrRkRk+flZXz7oZ7ujX9NUq64bEZHl6Fj/CHEzVs4w6gaC\nO/rUOJO/qmNpKehFRObhWP8wzY01xErMQ1+stamWsUyOkfTEjPstJgW9iMg8HOsfmXHETUGha6ea\nH8iW9Q1TIiI/7+5/4tj5ZXfn0KkUV61bPetxhS8JPzM8zvrWhkWr30x0Ry8iMkejmQnGMjlaZnhY\nqiAM0yCUFfRmtt3MXjCzQ2b22RLbf8PMTpvZT4LXbUXbbjWzl4LXrZWsvIhINfQHwyVbgikOZnJ+\nYrMqjryZtevGzOLAPcANQA+w38z2uvtzU3b9S3e/fcqxLcCdQCfgwJPBsQMVqb2ISBW8FvRz6KOv\n4lj6cu7otwCH3P2wu6eBPcDNZZ7/fcBD7t4fhPtDwPb5VVVEJBzmEvR1NXFW1CaqOrFZOR/GrgWO\nF633AFtL7PdBM3s38CLwaXc/Ps2xa0tdxMx2AjsB2tvb6e7uBiCVSp1fjgK1J9zUnnCrZnvqiu7I\nh/qyrKiBlYMvlty3u/vwpPWG+ATPHz5Od/fpSeVL1Z5Kjbr5v8AD7j5uZv8K+Brwi3M5gbvvAnYB\ndHZ2eldXFwDd3d0UlqNA7Qk3tSfcqtme4lE3p54/TPMKZ6ztspL7dm1dP2m94/nHiCVidHVdO6l8\nqdpTTtdNL7CuaL0jKDvP3fvcvfB7yb3ANeUeKyKy3AwMzzxr5VStjcnQj7rZD2w2s41mlgRuAfYW\n72BmlxSt3gQ8Hyw/CNxoZs1m1gzcGJSJiCxL2YkcQ6OZuQV9U21Vv05w1q4bd8+a2e3kAzoO7Hb3\ng2Z2F3DA3fcCnzKzm4As0A/8RnBsv5l9gfwPC4C73L1/EdohIrIk+obTOOV9EFvQ1pSkfzjNRM6J\nx2aeMmExlNVH7+77gH1Tyj5XtHwHcMc0x+4Gdi+gjiIioXEsmLVyXXP5T7m2NibJOQyOpM+Pq19K\nejJWRGQOjvQN01SboK1pbl03UL2x9Ap6EZEyuTtHzgyzsa0Rm2XWymKFaRCqNZZeQS8iUqb+4TRD\noxk2tjXO6bg156dB0B29iEioHTkzDDDnoK/2fDcKehGRMh05M0xjMs5FK+b2gerq+hpiBmd0Ry8i\nEm5H+obZMMf+eYBYzGhprN5YegW9iEgZBobTDI7MvX++oK0pqTt6EZEwm2//fEFrU1J99CIiYfZM\n7xCNtQnaV9bN6/jWxlqNoxcRCauDrwzxwqvneOdlrcTm2D9fkL+jV9CLiITSn3a/TG0ixrUbW+d9\njramWlLjWcYyExWsWXkU9CIiMzh8OsW+Z05w7aZW6pPxeZ+nMGVCNbpvFPQiIjP4yg9eJhmP8c7L\n5n83D/k+eqjOQ1MKehGRabz06jm++VQvO7asZ0VdzYLOVc35bhT0IiIluDt37j1IY22CT12/ecHn\nawumQajGWHoFvYhICfueOcljL/fxmfe9cU5fMjKdwh19NUbeKOhFRKYYSWf5D3/3HJdfspJf37J+\n9gPK0JBMUF8Tr0offVnfMCUi8vPkj7/3EieGxviTHVdX9Kv/WpuSGnUjIlJt/+/4IPf+8DA7tqyn\nc0NLRc/d1lTLqXNjFT1nOcq6ozez7cCXyH85+L3ufveU7b8L3Eb+y8FPA7/l7j8Ltk0AzwS7HnP3\nmypUdxGRBbn/iWOT1idyztef+BlrVtRyxwfeVPHrrW2u52DvUMXPO5tZ7+jNLA7cA7wfuBzYYWaX\nT9ntx0Cnu18JfAP4L0XbRt39quClkBeR0PrBi6f46clzfOHmK1i5wOGUpaxrbqB3cJRczit+7pmU\n03WzBTjk7ofdPQ3sAW4u3sHd/8HdR4LVx4GOylZTRGRxvfjqOb7//CluetvruPEtFy/KNTqa68lM\nOK8ucfdNOUG/FjhetN4TlE3n48DfF63XmdkBM3vczH5lHnUUEVlUZ86Ns2f/MdpX1vGffu2ti3ad\ndS0NAPQMjC7aNUox95l/hTCzDwHb3f22YP1jwFZ3v73Evh8Fbgfe4+7jQdlad+81s03Aw8D17v5y\niWN3AjsB2tvbr9mzZw8AqVSKpqamBTQxXNSecFN7wq2c9vSXGNUy3Tj4/uE059LOPU9nGc7A71yd\nYHNr6a8JLHXe6Ux3vROpHHc8Osq/fGuS69bWVPTPZ9u2bU+6e2epbeV8GNsLrCta7wjKJjGz9wJ/\nQFHIA7h7b/B+2My6gauBC4Le3XcBuwA6Ozu9q6sLgO7ubgrLUaD2hJvaE27ltGfqB6wAXVtLj4W/\n5+FD7H7qCGfTxq3v3EBjW9O0+5Y673SmO8dYZoI7Hv0OKy7eQFfX5iX78ymn62Y/sNnMNppZErgF\n2Fu8g5ldDXwVuMndTxWVN5tZbbDcBlwHPFepyouIzNfzJ87y1UdeZjid5beu28imtsX/zaeuJv/F\n4j0DI7PvXEGz3tG7e9bMbgceJD+8cre7HzSzu4AD7r4X+CLQBPyf4EtzC8Mo3wx81cxy5H+o3O3u\nCnoRqRp3Z8/+43x+70FqEzF2/sJlXLxqft8aNR8dzfUc71/aPvqyxtG7+z5g35SyzxUtv3ea4x4D\nFu+TDRGROehLjXPn3oN8++kT/MLmNt71+rYFz0o5V+taGnjq2MCSXlNPxopI5Lk733yqh/f+0Q94\n8OBJfu99b+Rrv7llyUMe8nf0rwyOkZ3ILdk1NdeNiETa0TPDfPDPHuOpY4O8ff1q7v7glbyhfUXV\n6rOuuYGJnHPy7NKNpVfQi0jkuDuHTqV49NAZXjqVYmVdgl+9ei3XXNrMgaMDHDi6tF0nxTqal34s\nvYJeRCKjd3CUH7x4mqd+NsDp1DgrahO87/J23nFZG8lEOHqq17XUA3C8f4Q1S3RNBb2ILGtDoxn+\n/pkTfOvHvTxxpB+A9S0N/PNrOnjr2lUk4uEI+IJLVtVjlr+jX7NEHxEo6EVk2XF3Hj/cz1/uP8a+\nZ0+SzubY1NbI797wBgxobSr9dGsYJBMxLllZx/GBEa6+aGmuqaAXkWVjYCzHn3Yf4q/2H+do3wgr\n6hJ8uHMdH7qmgys7VmFmc3qCtVo6mhvyffQKehH5eVMqpPuH06xqqOHvnn6FJw6P4rzAlo0tfOr6\nzbz/ikuoT8arUNOF6Wiu5/HDfeSfQV18CnoRCY1sLsfJoTF6BkbpGRjhaN/I+cnE2pqS3LA+xhVv\neD1tK2r5tbcv39nQO1oaOPmTXrK5hiW5noJeRKpmcCTN/qMD7D/az/6j/TzTM0Q2+FKOxmSc9S0N\nvPOyVi5b08RFK2qp73uBsRXh7X8v14bWBnIOJ4aX5gtIFPQismRePTvGj47kQ/1HR/r56clzQP4D\nyrd1rOIdm1rpaGmgo7me1fU1BHNnRc6Wjfnvon2+b2JJrqegF5FFkc7meP7EWf7HDw9zrH+E4/0j\nDIxkgHywX9rSwA2Xt7OhtZGO5npqQjYMcjF1NDewobWBg33js+9cAQp6EZmX7ESOk2fH6B0YpXdw\n9Px7T9F6OpjPZWVdgvUtDbxjUysb2hq5ZFU98Vg079bL9c7Xt/HNA8fITOQW/Yecgl5EShrPTvDK\nYCHIR+gdyId4z+AoL756jrOjGaZ+x3VTbYLVDTWsbkhy7aYW1jY3sL6lgVX1lX8yaDkMo5zJu17f\nxv1PHOPpnkGuubRlUa+loBeJKHdnPOucOjfG8PgEw+NZUuPZovfXyoZGM/QNp+lLjdM/nOZMKs2Z\n1ORuBQNW1tewuqGGDa2NrG6oobk+eT7YVzfU/Fx1vyzUOza1YsA/HupT0IvIZLmcczo1Ts/ASDAM\nMf86MTTKwEiGc6MZhoJXNufwve/Pes66mhgXr6yjtamWdS0NXLVuNZesqmdtcz0/PXGW5oYkK+tr\nfu67WyqpuTHJ+pUxHj10hk9dv3lRr6WgFwmJ8ewEA8MZ+ofTDIyk6RtOMzCcf391aIyeoPvk+MAo\nE1P6TBqTcVY3JGlIxmmsTdC2opb6mjgr0n3EVl1MbSJGbSJObU2M2kSMZDxGbU08v5yIEZtmdEs6\nm2PTmuh8uXjYvKU1zkPHBhhJZ2lILl4cK+hFFkEu55wdKwrt1OTw7h/O0D88Tv9I/n1gOENqPDvt\n+ZpqEzQHXSTXXRZ0mzQkz5dNNzNj3ZlBxtpaF6uZskCXt8bYd8T50ZF+ut64ePMhKOhFSpjIOels\njvHsBOPZHOOZHGfH8t0hgyMZBkbSwXKawZEMg6MZhoLy/CtzwV13QU3caEwmaKiN05hM0NpYy7rm\nBhprE/k78mTiteXaBPU1cXWZRNTm5jj1NXH+/NEjvHvzGmKL9OesoJdlaTw7wbmxbPDKkBrLcjZY\nLpSnxjOMZV4L63xwB+uZXFFZEObZHCNjabLf3Xf+6czZ1NfESSZi1NfEqU/GaUjG2djWxBW1hcCO\n05BMTFoOy7zoUn21cePf/dKb+fd/8yy7fniYf/2eyxblOmUFvZltB75Efgaee9397inba4G/AK4B\n+oAPu/vRYNsdwMeBCeBT7v5gxWovoZPLOdmck57IMZaZYCyTD9H8co7x4vXsa2Vj2Ryj6fz+o5nC\ne75sJJ0fGVII9bNjWdLZ2b9vsyZu1MRj1MRjJGJGIm4kYlOW40Z9Mkk8ZiRiRl16EGtsnbS9cExd\nUZjXJ/N3YhplIgv10a3reezQGf7wwfxkbW9f31zxa8wa9GYWB+4BbgB6gP1mttfdnyva7ePAgLu/\n3sxuAf4z8GEzuxy4BXgL8Drge2b2BndflOd+Xzh5jqa6fF9mfU18wY9Puzs5z787kHPHnfyL/HIu\n2OaF/Zwp+762PedO32iOnoGRSecpXCMX7JOZyDGRczITzkTOyU7kyOacbC5HNijL5JyJXO7CfSY8\neC86JijPn7P43FOOyeVK7PPaenEdCtcYS2ewh78TlOUuGFc9V4lYPpyTidikoK6ribGiLsGaplrq\namLU1cSprYlTl8gv1wUfLOaX8x88zqe7o+7MOcbaLl5YI0TmwMy4+4NX8kzvD/nk/T/mu59+N421\nle1sKedsW4BD7n44qNQe4GagOOhvBj4fLH8D+LLlU/ZmYI+7jwNHzOxQcL5/qkz1J/uVe/6R0Uz+\nZ0jM8v8DC//UzeD8WtGbk//Pa4HtCw6rWf3gHxb5Aq+JGcTMiMWMuBkxg3jMzpfFzIjHgn3Mgm0U\n7Z/frzZh1E8pixkkxwfxhuZJ54nH8q9EPEZN4T0I7UKQJ6asF8qmG/0hEmWr6mv4kx1X8+Kr52hY\nhGmXywn6tcDxovUeYOt0+7h71syGgNag/PEpx64tdREz2wnsDFZTZvZCsNwGnCmjnsuF2hNuak+4\nLXp7PrK057igPbfM/7KXTrchNB/GuvsuYNfUcjM74O6dVajSolB7wk3tCTe1Z37K+SSpF1hXtN4R\nlJXcx8wSwCryH8qWc6yIiCyicoJ+P7DZzDaaWZL8bxZ7p+yzF7g1WP4Q8LC7e1B+i5nVmtlGYDPw\no8pUXUREyjFr103Q53478CD54ZW73f2gmd0FHHD3vcCfA/8r+LC1n6CbKdjvr8h/cJsFPjGPETcX\ndOcsc2pPuKk94ab2zIPlb7xFRCSq9LSHiEjEKehFRCIutEFvZtvN7AUzO2Rmn612fRbCzNaZ2T+Y\n2XNmdtDMfrvadaoEM4ub2Y/N7NvVrstCmdlqM/uGmf3UzJ43s3dUu04LYWafDv6uPWtmD5hZXbXr\nNFdmttvMTpnZs0VlLWb2kJm9FLxXfr6ARTJNe74Y/J172sy+ZWarF+PaoQz6omkX3g9cDuwIplNY\nrrLAv3X3y4FrgU8s8/YU/DbwfLUrUSFfAr7j7m8C3sYybpeZrQU+BXS6+xXkB1Es4DmcqrkP2D6l\n7LPA9919M/D9YH25uI8L2/MQcIW7Xwm8CNyxGBcOZdBTNO2Cu6eBwrQLy5K7n3D3p4Llc+RDpOQT\nwsuFmXUAvwTcW+26LJSZrQLeTX70GO6edvfB6tZqwRJAffBcSwPwSpXrM2fu/gj5UXzFbga+Fix/\nDfiVJa3UApRqj7t/190LX0TwOPlnjSourEFfatqFZR2MBWa2AbgaeKK6NVmwPwZ+H5h9Gsnw2wic\nBv5n0BV1r5k1VrtS8+XuvcAfAseAE8CQu3+3urWqmHZ3PxEsnwTaq1mZCvst4O8X48RhDfpIMrMm\n4K+B33H3s9Wuz3yZ2S8Dp9z9yWrXpUISwNuBP3P3q4FhlleXwCRBv/XN5H+AvQ5oNLOPVrdWlRc8\nlBmJ8eFm9gfku3i/vhjnD2vQR27qBDOrIR/yX3f3b1a7Pgt0HXCTmR0l3632i2b2v6tbpQXpAXrc\nvfBb1jfIB/9y9V7giLufdvcM8E3gnVWuU6W8amaXAATvp6pcnwUzs98Afhn4iC/Sg01hDfpypl1Y\nNoIpm/8ceN7d/6ja9Vkod7/D3TvcfQP5P5uH3X3Z3jG6+0nguJm9MSi6nsnTcC83x4Brzawh+Lt3\nPcv4w+UpiqdbuRX42yrWZcFAJEUAAACtSURBVMGCL3X6feAmdx9ZrOuEMuiDDycK0y48D/yVux+s\nbq0W5DrgY+TvfH8SvD5Q7UrJJJ8Evm5mTwNXAf+xyvWZt+A3k28ATwHPkP93vuymDjCzB8h/d8Ub\nzazHzD4O3A3cYGYvkf/N5e6ZzhEm07Tny8AK4KEgF76yKNfWFAgiItEWyjt6ERGpHAW9iEjEKehF\nRCJOQS8iEnEKehGRiFPQi4hEnIJeRCTi/j/ciiTE8de7vAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8foacCfrKEq",
        "colab_type": "code",
        "outputId": "8a5aec7f-fc51-43c6-cf23-68a80c135821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "p_1=np.percentile(tfidf_vec.idf_,10)\n",
        "p_2=np.percentile(tfidf_vec.idf_,60)\n",
        "print(p_1,\"  \",p_2)\n",
        "\n",
        "vocab_2=[]\n",
        "for value in zip(tfidf_vec.vocabulary_.keys(),tfidf_vec.idf_):\n",
        "  if(value[1]>=p_1 and value[1]<=p_2):\n",
        "    vocab_2.append(value[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.568773809912135    11.215093649607276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM3dg6hBfqAH",
        "colab_type": "code",
        "outputId": "d50aa312-acf2-4fc7-f290-63111caf046c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(vocab_2)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25732"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0woxs_ta17PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_dict_2=dict(zip(vocab_2,list(range(1,len(vocab_2)+1))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_jhp6zGrKDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_essay_train_2=[]\n",
        "for sent in essay:\n",
        "  if(len(set(sent.split()).intersection(set(vocab_2)))>=1):\n",
        "    vector=[]\n",
        "    for word in sent.split():\n",
        "      if(word in vocab_2):\n",
        "        vector.append(word_dict_2[word])\n",
        "    new_essay_train_2.append(vector)  \n",
        "  else:\n",
        "    vector=[]\n",
        "    for word in sent.split():\n",
        "      vector.append(0)\n",
        "    new_essay_train_2.append(vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R505b6RFrJXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_essay_test_2=[]\n",
        "for sent in x_test[\"essay\"].values:\n",
        "  if(len(set(sent.split()).intersection(set(vocab_2)))>=1):\n",
        "    vector=[]\n",
        "    for word in sent.split():\n",
        "      if(word in vocab_2):\n",
        "        vector.append(word_dict_2[word])\n",
        "    new_essay_test_2.append(vector)  \n",
        "  else:\n",
        "    vector=[]\n",
        "    for word in sent.split():\n",
        "      vector.append(0)\n",
        "    new_essay_test_2.append(vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4B6SV9fsWU-",
        "colab_type": "code",
        "outputId": "159793f5-c4df-48de-87a2-6c56f69f38c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pd.DataFrame(new_essay_train_2).shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(81936, 196)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UysPxC9yrJT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_review_length = 300\n",
        "essay_train_2 = sequence.pad_sequences(new_essay_train_2, maxlen=max_review_length)\n",
        "essay_test_2= sequence.pad_sequences(new_essay_test_2, maxlen=max_review_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pPT3rfXj5hX5",
        "colab": {}
      },
      "source": [
        "text_input_layer=Input(shape=(300,))\n",
        "school_input_layer=Input(shape=(1,))\n",
        "teacher_prefix_input_layer=Input(shape=(1,))\n",
        "project_grade_input_layer=Input(shape=(1,))\n",
        "categories_input_layer=Input(shape=(1,))\n",
        "subcategories_input_layer=Input(shape=(1,))\n",
        "number_input_layer=Input(shape=(2,))\n",
        "\n",
        "embedding_layer_text=Embedding(len(vocab_2), 30 , input_length=300)(text_input_layer)\n",
        "lstm_layer=LSTM(70,input_shape=(300,30))(embedding_layer_text)\n",
        "#flatten=Flatten()(lstm_layer) # did not use this because output of LSTM for each sequence is a vector.\n",
        "embedding_layer_school=Embedding(len(states),3 , input_length=1)(school_input_layer)\n",
        "flatten_1=Flatten()(embedding_layer_school)\n",
        "embedding_layer_teacher_prefix=Embedding(len(prefixes),2,input_length=1)(teacher_prefix_input_layer)\n",
        "flatten_2=Flatten()(embedding_layer_teacher_prefix)\n",
        "embedding_layer_project_grade=Embedding(len(grades),2,input_length=1)(project_grade_input_layer)\n",
        "flatten_3=Flatten()(embedding_layer_project_grade)\n",
        "embedding_layer_categories=Embedding(len(categories),3,input_length=1)(categories_input_layer)\n",
        "flatten_4=Flatten()(embedding_layer_categories)\n",
        "embedding_layer_subcategories=Embedding(len(subcategories),8,input_length=1)(subcategories_input_layer)\n",
        "flatten_5=Flatten()(embedding_layer_subcategories)\n",
        "dense_layer_num=Dense(6,activation=\"relu\",kernel_initializer=\"he_normal\")(number_input_layer)\n",
        "\n",
        "concat_layer=concatenate([lstm_layer,flatten_1,flatten_2,flatten_3,flatten_4,flatten_5,dense_layer_num])\n",
        "\n",
        "dropout_layer_after_concat=Dropout(0.2)(concat_layer)\n",
        "dense_layer_after_concat=Dense(16,activation=\"relu\",kernel_initializer=\"he_normal\")(dropout_layer_after_concat)\n",
        "dropout_after_dense=Dropout(0.5)(dense_layer_after_concat)\n",
        "dense_layer_2=Dense(16,activation=\"relu\",kernel_initializer=\"he_normal\")(dropout_after_dense)\n",
        "dropout_2=Dropout(0.5)(dense_layer_2)\n",
        "dense_layer_3=Dense(6,activation=\"relu\",kernel_initializer=\"he_normal\")(dropout_2)\n",
        "bn=BatchNormalization()(dense_layer_3)\n",
        "\n",
        "output_layer=Dense(1, activation=\"sigmoid\")(bn)\n",
        "\n",
        "model_2=Model(inputs=[text_input_layer,school_input_layer,teacher_prefix_input_layer,project_grade_input_layer,categories_input_layer,subcategories_input_layer,number_input_layer],outputs=output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOlg1cpxhzJ7",
        "colab_type": "code",
        "outputId": "1ffb34f1-e651-4471-f85a-21cca8206d97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 300)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 300, 30)      771960      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 1, 3)         153         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 1, 2)         10          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 1, 2)         8           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 1, 3)         153         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 1, 8)         3176        input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            (None, 2)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 70)           28280       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 3)            0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 2)            0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 2)            0           embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 3)            0           embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 8)            0           embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 6)            18          input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 94)           0           lstm_1[0][0]                     \n",
            "                                                                 flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "                                                                 flatten_4[0][0]                  \n",
            "                                                                 flatten_5[0][0]                  \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 94)           0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 16)           1520        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 16)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 16)           272         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 16)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 6)            102         dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 6)            24          dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            7           batch_normalization_1[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 805,683\n",
            "Trainable params: 805,671\n",
            "Non-trainable params: 12\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u3YWSgps5wfR",
        "colab": {}
      },
      "source": [
        "model_2.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[auc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MY2Riix956Dq",
        "outputId": "cde68481-6c6f-4e0c-f58c-26c44b64e99d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "history_2=model_2.fit([np.array(essay_train_2),np.array(school_state_train),np.array(teacher_prefix_train),np.array(project_grade_train),np.array(categories_train),np.array(subcategories_train),np.array(num_variable_train)],y_train,epochs=15,batch_size=128,verbose=1,validation_data=([np.array(essay_test_2),np.array(school_state_test),np.array(teacher_prefix_test),np.array(project_grade_test),np.array(categories_test),np.array(subcategories_test),np.array(num_variable_test)],y_test))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 81936 samples, validate on 27312 samples\n",
            "Epoch 1/15\n",
            "81936/81936 [==============================] - 339s 4ms/step - loss: 0.5049 - auc: 0.4965 - val_loss: 0.4248 - val_auc: 0.5013\n",
            "Epoch 2/15\n",
            "81936/81936 [==============================] - 340s 4ms/step - loss: 0.4243 - auc: 0.5063 - val_loss: 0.4155 - val_auc: 0.5183\n",
            "Epoch 3/15\n",
            "81936/81936 [==============================] - 343s 4ms/step - loss: 0.4076 - auc: 0.5445 - val_loss: 0.3977 - val_auc: 0.5682\n",
            "Epoch 4/15\n",
            "81936/81936 [==============================] - 338s 4ms/step - loss: 0.3902 - auc: 0.5914 - val_loss: 0.3881 - val_auc: 0.6100\n",
            "Epoch 5/15\n",
            "81936/81936 [==============================] - 340s 4ms/step - loss: 0.3801 - auc: 0.6259 - val_loss: 0.3919 - val_auc: 0.6380\n",
            "Epoch 6/15\n",
            "81936/81936 [==============================] - 340s 4ms/step - loss: 0.3692 - auc: 0.6497 - val_loss: 0.3911 - val_auc: 0.6589\n",
            "Epoch 7/15\n",
            "81936/81936 [==============================] - 339s 4ms/step - loss: 0.3598 - auc: 0.6682 - val_loss: 0.3957 - val_auc: 0.6755\n",
            "Epoch 8/15\n",
            "81936/81936 [==============================] - 341s 4ms/step - loss: 0.3496 - auc: 0.6832 - val_loss: 0.3974 - val_auc: 0.6896\n",
            "Epoch 9/15\n",
            "81936/81936 [==============================] - 347s 4ms/step - loss: 0.3384 - auc: 0.6966 - val_loss: 0.4022 - val_auc: 0.7019\n",
            "Epoch 10/15\n",
            "81936/81936 [==============================] - 333s 4ms/step - loss: 0.3280 - auc: 0.7078 - val_loss: 0.4108 - val_auc: 0.7126\n",
            "Epoch 11/15\n",
            "81936/81936 [==============================] - 331s 4ms/step - loss: 0.3291 - auc: 0.7173 - val_loss: 0.4157 - val_auc: 0.7208\n",
            "Epoch 12/15\n",
            "81936/81936 [==============================] - 333s 4ms/step - loss: 0.3149 - auc: 0.7255 - val_loss: 0.4202 - val_auc: 0.7290\n",
            "Epoch 13/15\n",
            "81936/81936 [==============================] - 333s 4ms/step - loss: 0.3055 - auc: 0.7328 - val_loss: 0.4292 - val_auc: 0.7364\n",
            "Epoch 14/15\n",
            "81936/81936 [==============================] - 338s 4ms/step - loss: 0.2966 - auc: 0.7402 - val_loss: 0.4338 - val_auc: 0.7433\n",
            "Epoch 15/15\n",
            "81936/81936 [==============================] - 339s 4ms/step - loss: 0.2862 - auc: 0.7466 - val_loss: 0.4580 - val_auc: 0.7497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E4ZfqN-GcbJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "958aafd3-32cd-4c76-9e8b-27b4c4fe6c44"
      },
      "source": [
        "scores=model_2.evaluate([np.array(essay_test_2),np.array(school_state_test),np.array(teacher_prefix_test),np.array(project_grade_test),np.array(categories_test),np.array(subcategories_test),np.array(num_variable_test)],y_test,verbose=0)\n",
        "print(\"Loss =\",scores[0],\"\\nAUC =\",scores[1])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.4579841393647867 \n",
            "AUC = 0.7479469939917937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AMsPhMXasMr",
        "colab_type": "text"
      },
      "source": [
        "===================================================================================================\n",
        "# Model-3\n",
        "==================================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opA6fhNuGy8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vec_1 = CountVectorizer(lowercase=False,binary=True)\n",
        "school_state_train_ohe = count_vec_1.fit_transform(x_train[\"school_state\"].values)\n",
        "school_state_test_ohe = count_vec_1.transform(x_test[\"school_state\"].values)  \n",
        "\n",
        "count_vec_2 = CountVectorizer(lowercase=False,binary=True)\n",
        "teacher_prefix_train_ohe = count_vec_2.fit_transform(x_train[\"teacher_prefix\"].values)\n",
        "teacher_prefix_test_ohe = count_vec_2.transform(x_test[\"teacher_prefix\"].values) \n",
        "\n",
        "count_vec_3 = CountVectorizer(lowercase=False,binary=True)\n",
        "project_grade_train_ohe = count_vec_3.fit_transform(x_train[\"project_grade_category\"].values)\n",
        "project_grade_test_ohe = count_vec_3.transform(x_test[\"project_grade_category\"].values)\n",
        "\n",
        "count_vec_4 = CountVectorizer(lowercase=False,binary=True)\n",
        "categories_train_ohe = count_vec_4.fit_transform(x_train[\"clean_categories\"].values)\n",
        "categories_test_ohe = count_vec_4.transform(x_test[\"clean_categories\"].values) \n",
        "\n",
        "count_vec_5 = CountVectorizer(lowercase=False,binary=True)\n",
        "subcategories_train_ohe = count_vec_5.fit_transform(x_train[\"clean_subcategories\"].values)\n",
        "subcategories_test_ohe = count_vec_5.transform(x_test[\"clean_subcategories\"].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_6QBWQXY49sd",
        "colab": {}
      },
      "source": [
        "from scipy.sparse import hstack\n",
        "other_than_text_train=hstack((school_state_train_ohe,teacher_prefix_train_ohe,project_grade_train_ohe,categories_train_ohe,subcategories_train_ohe,num_variable_train)).toarray()\n",
        "other_than_text_test=hstack((school_state_test_ohe,teacher_prefix_test_ohe,project_grade_test_ohe,categories_test_ohe,subcategories_test_ohe,num_variable_test)).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "898nW40LGzpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv1D\n",
        "\n",
        "input_1=Input(shape=(400,))\n",
        "input_2=Input(shape=(other_than_text_train.shape[1],1))\n",
        "\n",
        "embedding_text=Embedding(len(vocab),100,input_length=400)(input_1)\n",
        "lstm=LSTM(100,input_shape=(400,100))(embedding_text)\n",
        "#flatten=Flatten()(lstm) # did not use this because output of LSTM for each sequence is a vector.\n",
        "conv_layer_1=Conv1D(64,kernel_size=3,strides=2,activation=\"relu\",kernel_initializer=\"he_normal\",input_shape=(101,1))(input_2)\n",
        "dropout_1=Dropout(0.5)(conv_layer_1)\n",
        "conv_layer_2=Conv1D(32,kernel_size=3,strides=2,activation=\"relu\",kernel_initializer=\"he_normal\")(dropout_1)\n",
        "flatten_1=Flatten()(conv_layer_2)\n",
        "\n",
        "concat_layer=concatenate([lstm,flatten_1])\n",
        "\n",
        "dropout_after_concat=Dropout(0.2)(concat_layer)\n",
        "dense_1=Dense(32,activation=\"relu\",kernel_initializer=\"he_normal\")(dropout_after_concat)\n",
        "dropout_3=Dropout(0.5)(dense_1)\n",
        "dense_2=Dense(16,activation=\"relu\",kernel_initializer=\"he_normal\")(dropout_3)\n",
        "dropout_4=Dropout(0.5)(dense_2)\n",
        "dense_3=Dense(6,activation=\"relu\",kernel_initializer=\"he_normal\")(dropout_4)\n",
        "bn=BatchNormalization()(dense_3)\n",
        "output_layer=Dense(1,activation=\"sigmoid\")(bn)\n",
        "\n",
        "model_3=Model(inputs=[input_1,input_2],outputs=output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1HzxXp-l0Ja",
        "colab_type": "code",
        "outputId": "e3ecb757-dda3-4df8-f4c9-cf76131dfe8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "model_3.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 101, 1)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 50, 64)       256         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            (None, 400)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 50, 64)       0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 400, 100)     5047600     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 24, 32)       6176        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 100)          80400       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 768)          0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 868)          0           lstm_1[0][0]                     \n",
            "                                                                 flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 868)          0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 32)           27808       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 16)           528         dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 16)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 6)            102         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 6)            24          dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            7           batch_normalization_1[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 5,162,901\n",
            "Trainable params: 5,162,889\n",
            "Non-trainable params: 12\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTtrCHayGz5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_3.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=[auc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuNZYKAbG0HK",
        "colab_type": "code",
        "outputId": "97ccd142-6b0c-4c5b-f3fc-2fec136a3016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "history_3 = model_3.fit([np.array(essay_train),np.array(other_than_text_train).reshape(other_than_text_train.shape[0],other_than_text_train.shape[1],1)],y_train,epochs=15,batch_size=128,verbose=1,validation_data=([np.array(essay_test),np.array(other_than_text_test).reshape(other_than_text_test.shape[0],other_than_text_test.shape[1],1)],y_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 81936 samples, validate on 27312 samples\n",
            "Epoch 1/15\n",
            "81936/81936 [==============================] - 412s 5ms/step - loss: 0.4947 - auc: 0.5071 - val_loss: 0.4107 - val_auc: 0.5391\n",
            "Epoch 2/15\n",
            "81936/81936 [==============================] - 399s 5ms/step - loss: 0.4103 - auc: 0.5668 - val_loss: 0.4191 - val_auc: 0.5874\n",
            "Epoch 3/15\n",
            "81936/81936 [==============================] - 398s 5ms/step - loss: 0.3966 - auc: 0.6061 - val_loss: 0.4012 - val_auc: 0.6225\n",
            "Epoch 4/15\n",
            "81936/81936 [==============================] - 416s 5ms/step - loss: 0.3895 - auc: 0.6354 - val_loss: 0.3938 - val_auc: 0.6463\n",
            "Epoch 5/15\n",
            "81936/81936 [==============================] - 411s 5ms/step - loss: 0.3808 - auc: 0.6566 - val_loss: 0.4109 - val_auc: 0.6634\n",
            "Epoch 6/15\n",
            "81936/81936 [==============================] - 408s 5ms/step - loss: 0.3742 - auc: 0.6706 - val_loss: 0.4118 - val_auc: 0.6763\n",
            "Epoch 7/15\n",
            "81936/81936 [==============================] - 424s 5ms/step - loss: 0.3681 - auc: 0.6822 - val_loss: 0.3889 - val_auc: 0.6878\n",
            "Epoch 8/15\n",
            "81936/81936 [==============================] - 429s 5ms/step - loss: 0.3620 - auc: 0.6936 - val_loss: 0.4254 - val_auc: 0.6973\n",
            "Epoch 9/15\n",
            "81936/81936 [==============================] - 432s 5ms/step - loss: 0.3513 - auc: 0.7017 - val_loss: 0.3838 - val_auc: 0.7067\n",
            "Epoch 10/15\n",
            "81936/81936 [==============================] - 423s 5ms/step - loss: 0.3359 - auc: 0.7124 - val_loss: 0.4197 - val_auc: 0.7169\n",
            "Epoch 11/15\n",
            "81936/81936 [==============================] - 419s 5ms/step - loss: 0.3237 - auc: 0.7219 - val_loss: 0.4065 - val_auc: 0.7263\n",
            "Epoch 12/15\n",
            "81936/81936 [==============================] - 427s 5ms/step - loss: 0.3130 - auc: 0.7310 - val_loss: 0.4061 - val_auc: 0.7354\n",
            "Epoch 13/15\n",
            "81936/81936 [==============================] - 420s 5ms/step - loss: 0.2946 - auc: 0.7405 - val_loss: 0.4478 - val_auc: 0.7445\n",
            "Epoch 14/15\n",
            "81936/81936 [==============================] - 419s 5ms/step - loss: 0.2810 - auc: 0.7489 - val_loss: 0.4478 - val_auc: 0.7527\n",
            "Epoch 15/15\n",
            "81936/81936 [==============================] - 417s 5ms/step - loss: 0.2676 - auc: 0.7568 - val_loss: 0.4097 - val_auc: 0.7608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzSyqd_KtXLf",
        "colab_type": "code",
        "outputId": "3b322cee-f6a2-46d1-a02c-370f8e797386",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "scores=model_3.evaluate([np.array(essay_test),np.array(other_than_text_test).reshape(other_than_text_test.shape[0],other_than_text_test.shape[1],1)],y_test,verbose=0)\n",
        "print(\"Loss =\",scores[0],\"\\nAUC Score =\",scores[1])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.4096996249793633 \n",
            "AUC Score = 0.7594813393373272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZE9grNDuVKR",
        "colab_type": "text"
      },
      "source": [
        "===================================================================================\n",
        "# Conclusions:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Uv8SG1HuZns",
        "colab_type": "code",
        "outputId": "51c76d03-b82d-4f8f-c9c6-e65cc32a09ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "table=PrettyTable()\n",
        "table.field_names=(\"Model\",\"Loss\",\"AUC\")\n",
        "table.add_row((\"Model-1\",0.53,0.82))\n",
        "table.add_row((\"Model-2\",0.45,0.74))\n",
        "table.add_row((\"Model-3\",0.40,0.75))\n",
        "print(table)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+------+------+\n",
            "|  Model  | Loss | AUC  |\n",
            "+---------+------+------+\n",
            "| Model-1 | 0.53 | 0.82 |\n",
            "| Model-2 | 0.45 | 0.74 |\n",
            "| Model-3 | 0.4  | 0.75 |\n",
            "+---------+------+------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpJbbgzawOTG",
        "colab_type": "text"
      },
      "source": [
        "Model 1  gave 0.82 AUC score on test data,model-2 gave AUC score 0.74 and model-3 0.75.\n",
        "for model-1 and model-2 I used Adam as optimozer while for model-3  used RmsProp as optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeZQS8JhgDYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}